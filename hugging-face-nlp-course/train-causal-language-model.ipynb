{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f2916b-cc51-407d-b4e8-81081d57e050",
   "metadata": {},
   "source": [
    "* https://huggingface.co/learn/nlp-course/chapter7/6?fw=pt\n",
    "* https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter7/section6_pt.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f819ba-185f-4e82-8815-c084542e275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (3.2.0)\n",
      "Requirement already satisfied: evaluate in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: transformers[sentencepiece] in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (4.48.0)\n",
      "Requirement already satisfied: filelock in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (0.27.1)\n",
      "Requirement already satisfied: packaging in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers[sentencepiece]) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.5.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers[sentencepiece]) (5.29.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece]\n",
    "!pip install accelerate>=0.26.0\n",
    "#!apt install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9669fa6b-ca44-41b1-b58e-a5fe80bfe28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copy-and-paste the text below in your GitHub issue and FILL OUT the two last points.\n",
      "\n",
      "- `transformers` version: 4.48.0\n",
      "- Platform: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35\n",
      "- Python version: 3.12.2\n",
      "- Huggingface_hub version: 0.27.1\n",
      "- Safetensors version: 0.5.2\n",
      "- Accelerate version: 1.3.0\n",
      "- Accelerate config: \tnot found\n",
      "- PyTorch version (GPU?): 2.5.1 (True)\n",
      "- Tensorflow version (GPU?): not installed (NA)\n",
      "- Flax version (CPU?/GPU?/TPU?): not installed (NA)\n",
      "- Jax version: not installed\n",
      "- JaxLib version: not installed\n",
      "- Using distributed or parallel set-up in script?: <fill in>\n",
      "- Using GPU in script?: <fill in>\n",
      "- GPU type: NVIDIA GeForce RTX 4080 Laptop GPU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!transformers-cli env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e418cfd0-7759-4f69-9b6d-5486f1210e0f",
   "metadata": {},
   "source": [
    "# Gather the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "209d6b1e-8845-4172-a9f8-b8fb27bacc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_keyword_in_string(string, keywords):\n",
    "    for keyword in keywords:\n",
    "        if keyword in string:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc6d027-3626-474f-9ca0-c9303245b632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True\n"
     ]
    }
   ],
   "source": [
    "filters = [\"pandas\", \"sklearn\", \"matplotlib\", \"seaborn\"]\n",
    "example_1 = \"import numpy as np\"\n",
    "example_2 = \"import pandas as pd\"\n",
    "\n",
    "print(\n",
    "    any_keyword_in_string(example_1, filters), any_keyword_in_string(example_2, filters)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0214e5e2-7f67-42b5-b661-c1eda1beb9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def filter_streaming_dataset(dataset, filters):\n",
    "    filtered_dict = defaultdict(list)\n",
    "    total = 0\n",
    "    for sample in tqdm(iter(dataset)):\n",
    "        total += 1\n",
    "        if any_keyword_in_string(sample[\"content\"], filters):\n",
    "            for k, v in sample.items():\n",
    "                filtered_dict[k].append(v)\n",
    "    print(f\"{len(filtered_dict['content'])/total:.2%} of data after filtering.\")\n",
    "    return Dataset.from_dict(filtered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad34906-5a53-4380-a921-1eee825df42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will take a very long time to execute, so you should skip it and go to\n",
    "# the next one!\n",
    "from datasets import load_dataset\n",
    "\n",
    "split = \"train\"  # \"valid\"\n",
    "filters = [\"pandas\", \"sklearn\", \"matplotlib\", \"seaborn\"]\n",
    "\n",
    "data = load_dataset(f\"transformersbook/codeparrot-{split}\", split=split, streaming=True)\n",
    "filtered_data = filter_streaming_dataset(data, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e40419f-5530-45e4-9826-1f3d5da6ae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n",
       "        num_rows: 606720\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n",
       "        num_rows: 3322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict, load_dataset\n",
    "\n",
    "ds_train = load_dataset(\"huggingface-course/codeparrot-ds-train\", split=\"train\")\n",
    "ds_valid = load_dataset(\"huggingface-course/codeparrot-ds-valid\", split=\"validation\")\n",
    "\n",
    "raw_datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": ds_train,  # .shuffle().select(range(50000)),\n",
    "        \"valid\": ds_valid,  # .shuffle().select(range(500))\n",
    "    }\n",
    ")\n",
    "\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "103b0a72-01e6-461a-aeb0-186891d7286b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO_NAME: kmike/scikit-learn\n",
      "PATH: sklearn/utils/__init__.py\n",
      "COPIES: 3\n",
      "SIZE: 10094\n",
      "CONTENT: \"\"\"\n",
      "The :mod:`sklearn.utils` module includes various utilites.\n",
      "\"\"\"\n",
      "\n",
      "from collections import Sequence\n",
      "\n",
      "import numpy as np\n",
      "from scipy.sparse import issparse\n",
      "import warnings\n",
      "\n",
      "from .murmurhash import murm\n",
      "LICENSE: bsd-3-clause\n"
     ]
    }
   ],
   "source": [
    "for key in raw_datasets[\"train\"][0]:\n",
    "    print(f\"{key.upper()}: {raw_datasets['train'][0][key][:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c7b0c33-415c-4fe5-9ffc-6e191dea9e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample the train and valid data to quickly test the training loop.\n",
    "sample_raw_datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": ds_train.shuffle().select(range(50000)),\n",
    "        \"valid\": ds_valid.shuffle().select(range(500)),\n",
    "    }\n",
    ")\n",
    "\n",
    "sample_raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffb6eb02-33e6-4406-90bc-1b726a7b0fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO_NAME: mwv/scikit-learn\n",
      "PATH: sklearn/metrics/classification.py\n",
      "COPIES: 95\n",
      "SIZE: 67713\n",
      "CONTENT: \"\"\"Metrics to assess performance on classification task given classe prediction\n",
      "\n",
      "Functions named as ``*_score`` return a scalar value to maximize: the higher\n",
      "the better\n",
      "\n",
      "Function named as ``*_error`` \n",
      "LICENSE: bsd-3-clause\n"
     ]
    }
   ],
   "source": [
    "for key in sample_raw_datasets[\"train\"][0]:\n",
    "    print(f\"{key.upper()}: {sample_raw_datasets['train'][0][key][:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac084924-97a1-4a95-b77b-26261dba3c29",
   "metadata": {},
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b2e3745-38e0-4f41-99a0-8c4dd259b092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs length: 34\n",
      "Input chunk lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 117, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 41]\n",
      "Chunk mapping: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "context_length = 128\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"huggingface-course/code-search-net-tokenizer\"\n",
    ")\n",
    "\n",
    "outputs = tokenizer(\n",
    "    raw_datasets[\"train\"][:2][\"content\"],\n",
    "    truncation=True,\n",
    "    max_length=context_length,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_length=True,\n",
    ")\n",
    "\n",
    "print(f\"Input IDs length: {len(outputs['input_ids'])}\")\n",
    "print(f\"Input chunk lengths: {(outputs['length'])}\")\n",
    "print(f\"Chunk mapping: {outputs['overflow_to_sample_mapping']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef9e536-86c8-4693-be94-c46583fb6b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4dec10132945089502041291bc981f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbef03f1d73f4332b520d9c7f89561c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 1378510\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 13347\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"content\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "\n",
    "tokenized_datasets = sample_raw_datasets.map(\n",
    "    tokenize, batched=True, remove_columns=raw_datasets[\"train\"].column_names\n",
    ")\n",
    "# tokenized_datasets = raw_datasets.map(\n",
    "#    tokenize, batched=True, remove_columns=raw_datasets[\"train\"].column_names\n",
    "# )\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e042faa9-73e9-4b02-9353-87894fda4034",
   "metadata": {},
   "source": [
    "# Initialize a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "627cd983-f6d6-429f-8c23-24c8f3e1a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, GPT2LMHeadModel\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=context_length,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82f27e6b-2fbf-4b76-8c8c-62aa2b1d2965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 124.2M parameters\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel(config)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f678696-af72-41f8-a5d6-b3bc7d86fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083c6ff-8726-4fe8-93f3-76ecacda8d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = data_collator([tokenized_datasets[\"train\"][i] for i in range(5)])\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713f09c-1425-4099-beb5-60f22b2b2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f09bb47-a6c3-45f0-a7f9-4efc18eee825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`abs\n",
    "# https://stackoverflow.com/a/78610845/8492021\n",
    "!pip install accelerate\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b182d-494e-4e2e-99ee-26b25a53dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "\n",
    "print(accelerate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca13d9a-4d0e-479f-bdb4-e2de5df1a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"codeparrot-ds-sample\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5_000,\n",
    "    logging_steps=5_000,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=5_000,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"valid\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8da8ce-f7b9-4459-b9e0-bfa6b6d73b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a6334c-e4e0-4b39-95fc-30240007d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b28c4df-f62a-4a69-aa96-13eaba8544b3",
   "metadata": {},
   "source": [
    "# Generate code with a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be65571f-2632-41ee-b345-5bfc13c47163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# pipe = pipeline(\n",
    "#    \"text-generation\", model=\"renwei2024/codeparrot-ds-sample\", device=device\n",
    "# )\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=\"huggingface-course/codeparrot-ds\", device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62af1b5-5516-46c0-ad98-84cfc6676d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"\\\n",
    "# create some data\n",
    "x = np.random.randn(100)\n",
    "y = np.random.randn(100)\n",
    "\n",
    "# create scatter plot with x, y\n",
    "\"\"\"\n",
    "print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93dd246-e5de-4e3a-8a23-50226b8fca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"\\\n",
    "# create some data\n",
    "x = np.random.randn(100)\n",
    "y = np.random.randn(100)\n",
    "\n",
    "# create dataframe from x and y\n",
    "\"\"\"\n",
    "print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e7046a-8d51-4d48-ab2e-d420599a02b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"\\\n",
    "# dataframe with profession, income and name\n",
    "df = pd.DataFrame({'profession': x, 'income':y, 'name': z})\n",
    "\n",
    "# calculate the mean income per profession\n",
    "\"\"\"\n",
    "print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a0598-a717-4f77-8f69-de61bfdb622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"\n",
    "# import random forest regressor from scikit-learn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# fit random forest model with 300 estimators on X, y:\n",
    "\"\"\"\n",
    "print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaa06ca-9ec3-4977-a7cf-625ad268770a",
   "metadata": {},
   "source": [
    "# Train with Accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "289fcf52-18b1-4b5f-aad1-a6915d63467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword has not single token: testtest\n"
     ]
    }
   ],
   "source": [
    "keytoken_ids = []\n",
    "for keyword in [\n",
    "    \"plt\",\n",
    "    \"pd\",\n",
    "    \"sk\",\n",
    "    \"fit\",\n",
    "    \"predict\",\n",
    "    \" plt\",\n",
    "    \" pd\",\n",
    "    \" sk\",\n",
    "    \" fit\",\n",
    "    \" predict\",\n",
    "    \"testtest\",\n",
    "]:\n",
    "    ids = tokenizer([keyword]).input_ids[0]\n",
    "    if len(ids) == 1:\n",
    "        keytoken_ids.append(ids[0])\n",
    "    else:\n",
    "        print(f\"Keyword has not single token: {keyword}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "207fe5e9-3a71-431d-85cc-1a7b25a9c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "def keytoken_weighted_loss(inputs, logits, keytoken_ids, alpha=1.0):\n",
    "    # Shift so that tokens < n predict n\n",
    "    shift_labels = inputs[..., 1:].contiguous()\n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    # Calculate per-token loss\n",
    "    loss_fct = CrossEntropyLoss(reduce=False)\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    # Resize and average loss per sample\n",
    "    loss_per_sample = loss.view(shift_logits.size(0), shift_logits.size(1)).mean(axis=1)\n",
    "    # Calculate and scale weighting\n",
    "    weights = torch.stack([(inputs == kt).float() for kt in keytoken_ids]).sum(\n",
    "        axis=[0, 2]\n",
    "    )\n",
    "    weights = alpha * (1.0 + weights)\n",
    "    # Calculate weighted average\n",
    "    weighted_loss = (loss_per_sample * weights).mean()\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3213c6de-1922-4be1-8017-2952a773757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=32, shuffle=True)\n",
    "eval_dataloader = DataLoader(tokenized_datasets[\"valid\"], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba2e1a7d-aee6-4608-ba6e-4ac8fd07ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 0.1\n",
    "\n",
    "\n",
    "def get_grouped_params(model, no_decay=[\"bias\", \"LayerNorm.weight\"]):\n",
    "    params_with_wd, params_without_wd = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        if any(nd in n for nd in no_decay):\n",
    "            params_without_wd.append(p)\n",
    "        else:\n",
    "            params_with_wd.append(p)\n",
    "    return [\n",
    "        {\"params\": params_with_wd, \"weight_decay\": weight_decay},\n",
    "        {\"params\": params_without_wd, \"weight_decay\": 0.0},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb4460d0-6db5-46a0-ae08-ba09959517a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.huggingface.co/t/chapter-7-questions/11746/107?u=renwei2024\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch[\"input_ids\"], labels=batch[\"input_ids\"])\n",
    "        losses.append(accelerator.gather(outputs.loss.view(-1)))\n",
    "    loss = torch.mean(torch.cat(losses))\n",
    "    try:\n",
    "        perplexity = torch.exp(loss)\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "    return loss.item(), perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0afcd43-3dd7-4648-bcad-4c708244e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37f9b897-db37-49a6-932d-37c8f1e43807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(get_grouped_params(model), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d3bc5e9-693d-4ff4-b0d9-834e607f999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "# `accelerator = Accelerator(fp16=True)` leads to this TypeError:\n",
    "#   TypeError: Accelerator.__init__() got an unexpected keyword argument 'fp16'\n",
    "accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5443c42-e84d-4f1c-ae40-099c4a75ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 1\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=200,  # 1_000\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0972699-92f8-43a3-abd4-109a80db266d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'renwei2024/codeparrot-ds-sample-accelerate'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import Repository, get_full_repo_name\n",
    "\n",
    "model_name = \"codeparrot-ds-sample-accelerate\"\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54d95239-4ba0-4ba3-bda5-77a3d9c2bded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7561c467dd34e4195fba1eabcfe6aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "241c0029-e2cf-41de-841e-78c8d1e57a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository 'renwei2024/codeparrot-ds-sample-accelerate' created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a remote repo.\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Authenticate with your Hugging Face token\n",
    "api = HfApi()\n",
    "\n",
    "# Create the model repository on Hugging Face Hub\n",
    "api.create_repo(repo_id=repo_name)\n",
    "\n",
    "print(f\"Repository '{repo_name}' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "623dd6f3-2f32-476e-8b39-362d4bdc6d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/home/renwei/repos/github/renweizhukov/jupyter-lab-notebook/hugging-face-nlp-course/codeparrot-ds-sample-accelerate is already a clone of https://huggingface.co/renwei2024/codeparrot-ds-sample-accelerate. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"codeparrot-ds-sample-accelerate\"\n",
    "repo = Repository(local_dir=output_dir, clone_from=repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff0f437c-8de8-460f-9471-070a51e7f758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/renwei/repos/github/renweizhukov/jupyter-lab-notebook/hugging-face-nlp-course\n",
      "total 106M\n",
      "drwxr-xr-x 4 renwei renwei 4.0K Jan 28 12:33  .\n",
      "drwxr-xr-x 5 renwei renwei 4.0K Jan 28 11:19  ..\n",
      "drwxr-xr-x 2 renwei renwei 4.0K Jan 28 11:20  .ipynb_checkpoints\n",
      "-rw-r--r-- 1 renwei renwei 3.5K Jan 28 12:09 '=0.26.0'\n",
      "-rw-r--r-- 1 renwei renwei  53M Jan 27 18:35  NeMo-issues-fixed.jsonl\n",
      "-rw-r--r-- 1 renwei renwei  53M Jan 27 18:35  NeMo-issues.jsonl\n",
      "-rw-r--r-- 1 renwei renwei  33K Jan 27 18:35  build-new-tokenizer.ipynb\n",
      "drwxr-xr-x 3 renwei renwei 4.0K Jan 28 11:26  codeparrot-ds-sample-accelerate\n",
      "-rw-r--r-- 1 renwei renwei  36K Jan 28 11:24  datasets-library-create-your-owne-dataset.ipynb\n",
      "-rw-r--r-- 1 renwei renwei 100K Jan 27 18:35  datasets-library-time-to-slice-and-dice.ipynb\n",
      "-rw-r--r-- 1 renwei renwei  45K Jan 27 18:35  semantic-search-with-faiss.ipynb\n",
      "-rw-r--r-- 1 renwei renwei  46K Jan 28 12:33  train-causal-language-model.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls -alh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "567e239e-1218-4f74-947f-9731e9b8fbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.959161758422852, 57478.2421875)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f03c3ef-147c-49fc-b0ea-771746580707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84288c10aa6b47bb8da2be1fe58b102c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43079 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'samples': 3200, 'steps': 12, 'loss/train': 88.76261901855469}\n",
      "{'samples': 6400, 'steps': 24, 'loss/train': 120.48477935791016}\n",
      "{'samples': 9600, 'steps': 37, 'loss/train': 86.93660736083984}\n",
      "{'samples': 12800, 'steps': 49, 'loss/train': 72.72986602783203}\n",
      "{'samples': 16000, 'steps': 62, 'loss/train': 66.69828033447266}\n",
      "{'samples': 19200, 'steps': 74, 'loss/train': 71.48916625976562}\n",
      "{'samples': 22400, 'steps': 87, 'loss/train': 55.479026794433594}\n",
      "{'samples': 25600, 'steps': 99, 'loss/train': 78.30088806152344}\n",
      "{'samples': 28800, 'steps': 112, 'loss/train': 58.12162780761719}\n",
      "{'samples': 32000, 'steps': 124, 'loss/train': 65.84077453613281}\n",
      "{'samples': 35200, 'steps': 137, 'loss/train': 50.55690002441406}\n",
      "{'samples': 38400, 'steps': 149, 'loss/train': 63.242576599121094}\n",
      "{'samples': 41600, 'steps': 162, 'loss/train': 72.86725616455078}\n",
      "{'samples': 44800, 'steps': 174, 'loss/train': 59.62398147583008}\n",
      "{'samples': 48000, 'steps': 187, 'loss/train': 52.5299186706543}\n",
      "{'samples': 51200, 'steps': 199, 'loss/train': 44.426109313964844}\n",
      "{'samples': 54400, 'steps': 212, 'loss/train': 37.56553649902344}\n",
      "{'samples': 57600, 'steps': 224, 'loss/train': 47.6856689453125}\n",
      "{'samples': 60800, 'steps': 237, 'loss/train': 48.3265380859375}\n",
      "{'samples': 64000, 'steps': 249, 'loss/train': 48.380332946777344}\n",
      "{'samples': 67200, 'steps': 262, 'loss/train': 52.15728759765625}\n",
      "{'samples': 70400, 'steps': 274, 'loss/train': 40.81139373779297}\n",
      "{'samples': 73600, 'steps': 287, 'loss/train': 34.74638366699219}\n",
      "{'samples': 76800, 'steps': 299, 'loss/train': 40.33501434326172}\n",
      "{'samples': 80000, 'steps': 312, 'loss/train': 38.303321838378906}\n",
      "{'samples': 83200, 'steps': 324, 'loss/train': 45.95549011230469}\n",
      "{'samples': 86400, 'steps': 337, 'loss/train': 38.96587371826172}\n",
      "{'samples': 89600, 'steps': 349, 'loss/train': 39.898658752441406}\n",
      "{'samples': 92800, 'steps': 362, 'loss/train': 43.571659088134766}\n",
      "{'samples': 96000, 'steps': 374, 'loss/train': 40.070343017578125}\n",
      "{'samples': 99200, 'steps': 387, 'loss/train': 43.194053649902344}\n",
      "{'samples': 102400, 'steps': 399, 'loss/train': 34.442657470703125}\n",
      "{'samples': 105600, 'steps': 412, 'loss/train': 40.82957458496094}\n",
      "{'samples': 108800, 'steps': 424, 'loss/train': 38.47228240966797}\n",
      "{'samples': 112000, 'steps': 437, 'loss/train': 35.578636169433594}\n",
      "{'samples': 115200, 'steps': 449, 'loss/train': 37.864402770996094}\n",
      "{'samples': 118400, 'steps': 462, 'loss/train': 33.89698028564453}\n",
      "{'samples': 121600, 'steps': 474, 'loss/train': 37.718482971191406}\n",
      "{'samples': 124800, 'steps': 487, 'loss/train': 32.374900817871094}\n",
      "{'samples': 128000, 'steps': 499, 'loss/train': 32.371253967285156}\n",
      "{'samples': 131200, 'steps': 512, 'loss/train': 29.44904327392578}\n",
      "{'samples': 134400, 'steps': 524, 'loss/train': 40.97491455078125}\n",
      "{'samples': 137600, 'steps': 537, 'loss/train': 33.992393493652344}\n",
      "{'samples': 140800, 'steps': 549, 'loss/train': 30.829172134399414}\n",
      "{'samples': 144000, 'steps': 562, 'loss/train': 36.472103118896484}\n",
      "{'samples': 147200, 'steps': 574, 'loss/train': 31.52469253540039}\n",
      "{'samples': 150400, 'steps': 587, 'loss/train': 37.05902099609375}\n",
      "{'samples': 153600, 'steps': 599, 'loss/train': 35.146053314208984}\n",
      "{'samples': 156800, 'steps': 612, 'loss/train': 32.53689193725586}\n",
      "{'samples': 160000, 'steps': 624, 'loss/train': 35.73029708862305}\n",
      "{'samples': 163200, 'steps': 637, 'loss/train': 29.873388290405273}\n",
      "{'samples': 166400, 'steps': 649, 'loss/train': 31.35056495666504}\n",
      "{'samples': 169600, 'steps': 662, 'loss/train': 48.43894577026367}\n",
      "{'samples': 172800, 'steps': 674, 'loss/train': 34.11672592163086}\n",
      "{'samples': 176000, 'steps': 687, 'loss/train': 31.117591857910156}\n",
      "{'samples': 179200, 'steps': 699, 'loss/train': 30.11330795288086}\n",
      "{'samples': 182400, 'steps': 712, 'loss/train': 29.747909545898438}\n",
      "{'samples': 185600, 'steps': 724, 'loss/train': 36.29369354248047}\n",
      "{'samples': 188800, 'steps': 737, 'loss/train': 31.982460021972656}\n",
      "{'samples': 192000, 'steps': 749, 'loss/train': 28.494911193847656}\n",
      "{'samples': 195200, 'steps': 762, 'loss/train': 31.60004425048828}\n",
      "{'samples': 198400, 'steps': 774, 'loss/train': 33.07685852050781}\n",
      "{'samples': 201600, 'steps': 787, 'loss/train': 32.01637649536133}\n",
      "{'samples': 204800, 'steps': 799, 'loss/train': 29.269065856933594}\n",
      "{'samples': 208000, 'steps': 812, 'loss/train': 29.148460388183594}\n",
      "{'samples': 211200, 'steps': 824, 'loss/train': 34.068939208984375}\n",
      "{'samples': 214400, 'steps': 837, 'loss/train': 27.794113159179688}\n",
      "{'samples': 217600, 'steps': 849, 'loss/train': 34.30712890625}\n",
      "{'samples': 220800, 'steps': 862, 'loss/train': 30.4472713470459}\n",
      "{'samples': 224000, 'steps': 874, 'loss/train': 32.402130126953125}\n",
      "{'samples': 227200, 'steps': 887, 'loss/train': 32.92396545410156}\n",
      "{'samples': 230400, 'steps': 899, 'loss/train': 30.590503692626953}\n",
      "{'samples': 233600, 'steps': 912, 'loss/train': 25.633304595947266}\n",
      "{'samples': 236800, 'steps': 924, 'loss/train': 33.24501037597656}\n",
      "{'samples': 240000, 'steps': 937, 'loss/train': 22.76143455505371}\n",
      "{'samples': 243200, 'steps': 949, 'loss/train': 35.167362213134766}\n",
      "{'samples': 246400, 'steps': 962, 'loss/train': 31.844606399536133}\n",
      "{'samples': 249600, 'steps': 974, 'loss/train': 22.29014015197754}\n",
      "{'samples': 252800, 'steps': 987, 'loss/train': 29.86300277709961}\n",
      "{'samples': 256000, 'steps': 999, 'loss/train': 31.29414939880371}\n",
      "{'samples': 259200, 'steps': 1012, 'loss/train': 26.323802947998047}\n",
      "{'samples': 262400, 'steps': 1024, 'loss/train': 29.02971649169922}\n",
      "{'samples': 265600, 'steps': 1037, 'loss/train': 27.191017150878906}\n",
      "{'samples': 268800, 'steps': 1049, 'loss/train': 31.89646339416504}\n",
      "{'samples': 272000, 'steps': 1062, 'loss/train': 34.514404296875}\n",
      "{'samples': 275200, 'steps': 1074, 'loss/train': 24.2069091796875}\n",
      "{'samples': 278400, 'steps': 1087, 'loss/train': 25.581727981567383}\n",
      "{'samples': 281600, 'steps': 1099, 'loss/train': 23.197078704833984}\n",
      "{'samples': 284800, 'steps': 1112, 'loss/train': 24.632753372192383}\n",
      "{'samples': 288000, 'steps': 1124, 'loss/train': 23.962627410888672}\n",
      "{'samples': 291200, 'steps': 1137, 'loss/train': 35.06965637207031}\n",
      "{'samples': 294400, 'steps': 1149, 'loss/train': 32.27027130126953}\n",
      "{'samples': 297600, 'steps': 1162, 'loss/train': 29.31847381591797}\n",
      "{'samples': 300800, 'steps': 1174, 'loss/train': 28.3587646484375}\n",
      "{'samples': 304000, 'steps': 1187, 'loss/train': 25.56454849243164}\n",
      "{'samples': 307200, 'steps': 1199, 'loss/train': 29.189794540405273}\n",
      "{'samples': 310400, 'steps': 1212, 'loss/train': 25.784320831298828}\n",
      "{'samples': 313600, 'steps': 1224, 'loss/train': 26.84465789794922}\n",
      "{'samples': 316800, 'steps': 1237, 'loss/train': 23.800006866455078}\n",
      "{'samples': 320000, 'steps': 1249, 'loss/train': 32.3172607421875}\n",
      "{'loss/eval': 2.6224334239959717, 'perplexity': 13.76918888092041}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'samples': 323200, 'steps': 1262, 'loss/train': 27.817899703979492}\n",
      "{'samples': 326400, 'steps': 1274, 'loss/train': 22.731399536132812}\n",
      "{'samples': 329600, 'steps': 1287, 'loss/train': 26.90929412841797}\n",
      "{'samples': 332800, 'steps': 1299, 'loss/train': 35.88505554199219}\n",
      "{'samples': 336000, 'steps': 1312, 'loss/train': 26.756013870239258}\n",
      "{'samples': 339200, 'steps': 1324, 'loss/train': 23.115341186523438}\n",
      "{'samples': 342400, 'steps': 1337, 'loss/train': 27.553447723388672}\n",
      "{'samples': 345600, 'steps': 1349, 'loss/train': 22.172344207763672}\n",
      "{'samples': 348800, 'steps': 1362, 'loss/train': 21.983013153076172}\n",
      "{'samples': 352000, 'steps': 1374, 'loss/train': 25.516576766967773}\n",
      "{'samples': 355200, 'steps': 1387, 'loss/train': 24.908145904541016}\n",
      "{'samples': 358400, 'steps': 1399, 'loss/train': 25.049896240234375}\n",
      "{'samples': 361600, 'steps': 1412, 'loss/train': 23.811092376708984}\n",
      "{'samples': 364800, 'steps': 1424, 'loss/train': 29.2843074798584}\n",
      "{'samples': 368000, 'steps': 1437, 'loss/train': 24.848499298095703}\n",
      "{'samples': 371200, 'steps': 1449, 'loss/train': 31.82938575744629}\n",
      "{'samples': 374400, 'steps': 1462, 'loss/train': 25.55026626586914}\n",
      "{'samples': 377600, 'steps': 1474, 'loss/train': 30.71835708618164}\n",
      "{'samples': 380800, 'steps': 1487, 'loss/train': 33.070892333984375}\n",
      "{'samples': 384000, 'steps': 1499, 'loss/train': 27.445941925048828}\n",
      "{'samples': 387200, 'steps': 1512, 'loss/train': 38.838470458984375}\n",
      "{'samples': 390400, 'steps': 1524, 'loss/train': 24.901384353637695}\n",
      "{'samples': 393600, 'steps': 1537, 'loss/train': 23.288286209106445}\n",
      "{'samples': 396800, 'steps': 1549, 'loss/train': 21.972440719604492}\n",
      "{'samples': 400000, 'steps': 1562, 'loss/train': 30.89948081970215}\n",
      "{'samples': 403200, 'steps': 1574, 'loss/train': 26.071170806884766}\n",
      "{'samples': 406400, 'steps': 1587, 'loss/train': 25.03206443786621}\n",
      "{'samples': 409600, 'steps': 1599, 'loss/train': 24.56647491455078}\n",
      "{'samples': 412800, 'steps': 1612, 'loss/train': 22.869478225708008}\n",
      "{'samples': 416000, 'steps': 1624, 'loss/train': 25.736608505249023}\n",
      "{'samples': 419200, 'steps': 1637, 'loss/train': 21.630695343017578}\n",
      "{'samples': 422400, 'steps': 1649, 'loss/train': 22.561359405517578}\n",
      "{'samples': 425600, 'steps': 1662, 'loss/train': 20.411752700805664}\n",
      "{'samples': 428800, 'steps': 1674, 'loss/train': 24.301393508911133}\n",
      "{'samples': 432000, 'steps': 1687, 'loss/train': 26.626548767089844}\n",
      "{'samples': 435200, 'steps': 1699, 'loss/train': 25.454242706298828}\n",
      "{'samples': 438400, 'steps': 1712, 'loss/train': 24.985515594482422}\n",
      "{'samples': 441600, 'steps': 1724, 'loss/train': 20.238483428955078}\n",
      "{'samples': 444800, 'steps': 1737, 'loss/train': 21.831161499023438}\n",
      "{'samples': 448000, 'steps': 1749, 'loss/train': 30.847896575927734}\n",
      "{'samples': 451200, 'steps': 1762, 'loss/train': 30.850208282470703}\n",
      "{'samples': 454400, 'steps': 1774, 'loss/train': 21.052989959716797}\n",
      "{'samples': 457600, 'steps': 1787, 'loss/train': 19.717878341674805}\n",
      "{'samples': 460800, 'steps': 1799, 'loss/train': 30.684730529785156}\n",
      "{'samples': 464000, 'steps': 1812, 'loss/train': 22.002403259277344}\n",
      "{'samples': 467200, 'steps': 1824, 'loss/train': 27.548545837402344}\n",
      "{'samples': 470400, 'steps': 1837, 'loss/train': 19.49301528930664}\n",
      "{'samples': 473600, 'steps': 1849, 'loss/train': 22.40578842163086}\n",
      "{'samples': 476800, 'steps': 1862, 'loss/train': 31.424606323242188}\n",
      "{'samples': 480000, 'steps': 1874, 'loss/train': 27.061405181884766}\n",
      "{'samples': 483200, 'steps': 1887, 'loss/train': 24.652925491333008}\n",
      "{'samples': 486400, 'steps': 1899, 'loss/train': 19.566184997558594}\n",
      "{'samples': 489600, 'steps': 1912, 'loss/train': 31.877744674682617}\n",
      "{'samples': 492800, 'steps': 1924, 'loss/train': 29.407373428344727}\n",
      "{'samples': 496000, 'steps': 1937, 'loss/train': 25.503154754638672}\n",
      "{'samples': 499200, 'steps': 1949, 'loss/train': 22.703367233276367}\n",
      "{'samples': 502400, 'steps': 1962, 'loss/train': 21.528926849365234}\n",
      "{'samples': 505600, 'steps': 1974, 'loss/train': 22.839942932128906}\n",
      "{'samples': 508800, 'steps': 1987, 'loss/train': 23.999099731445312}\n",
      "{'samples': 512000, 'steps': 1999, 'loss/train': 21.026111602783203}\n",
      "{'samples': 515200, 'steps': 2012, 'loss/train': 26.828641891479492}\n",
      "{'samples': 518400, 'steps': 2024, 'loss/train': 19.556472778320312}\n",
      "{'samples': 521600, 'steps': 2037, 'loss/train': 20.19314956665039}\n",
      "{'samples': 524800, 'steps': 2049, 'loss/train': 25.061195373535156}\n",
      "{'samples': 528000, 'steps': 2062, 'loss/train': 24.757850646972656}\n",
      "{'samples': 531200, 'steps': 2074, 'loss/train': 26.888256072998047}\n",
      "{'samples': 534400, 'steps': 2087, 'loss/train': 20.330055236816406}\n",
      "{'samples': 537600, 'steps': 2099, 'loss/train': 22.941390991210938}\n",
      "{'samples': 540800, 'steps': 2112, 'loss/train': 28.369447708129883}\n",
      "{'samples': 544000, 'steps': 2124, 'loss/train': 25.96849250793457}\n",
      "{'samples': 547200, 'steps': 2137, 'loss/train': 27.765613555908203}\n",
      "{'samples': 550400, 'steps': 2149, 'loss/train': 19.98782730102539}\n",
      "{'samples': 553600, 'steps': 2162, 'loss/train': 30.772048950195312}\n",
      "{'samples': 556800, 'steps': 2174, 'loss/train': 20.344871520996094}\n",
      "{'samples': 560000, 'steps': 2187, 'loss/train': 23.209762573242188}\n",
      "{'samples': 563200, 'steps': 2199, 'loss/train': 21.48196029663086}\n",
      "{'samples': 566400, 'steps': 2212, 'loss/train': 22.299091339111328}\n",
      "{'samples': 569600, 'steps': 2224, 'loss/train': 18.482105255126953}\n",
      "{'samples': 572800, 'steps': 2237, 'loss/train': 26.003883361816406}\n",
      "{'samples': 576000, 'steps': 2249, 'loss/train': 22.68401336669922}\n",
      "{'samples': 579200, 'steps': 2262, 'loss/train': 23.691349029541016}\n",
      "{'samples': 582400, 'steps': 2274, 'loss/train': 23.83700942993164}\n",
      "{'samples': 585600, 'steps': 2287, 'loss/train': 25.929725646972656}\n",
      "{'samples': 588800, 'steps': 2299, 'loss/train': 21.075397491455078}\n",
      "{'samples': 592000, 'steps': 2312, 'loss/train': 22.994155883789062}\n",
      "{'samples': 595200, 'steps': 2324, 'loss/train': 24.932422637939453}\n",
      "{'samples': 598400, 'steps': 2337, 'loss/train': 27.572444915771484}\n",
      "{'samples': 601600, 'steps': 2349, 'loss/train': 18.372848510742188}\n",
      "{'samples': 604800, 'steps': 2362, 'loss/train': 19.794788360595703}\n",
      "{'samples': 608000, 'steps': 2374, 'loss/train': 20.780044555664062}\n",
      "{'samples': 611200, 'steps': 2387, 'loss/train': 26.56884002685547}\n",
      "{'samples': 614400, 'steps': 2399, 'loss/train': 29.640331268310547}\n",
      "{'samples': 617600, 'steps': 2412, 'loss/train': 23.65438461303711}\n",
      "{'samples': 620800, 'steps': 2424, 'loss/train': 22.247718811035156}\n",
      "{'samples': 624000, 'steps': 2437, 'loss/train': 24.414356231689453}\n",
      "{'samples': 627200, 'steps': 2449, 'loss/train': 26.491357803344727}\n",
      "{'samples': 630400, 'steps': 2462, 'loss/train': 18.55788803100586}\n",
      "{'samples': 633600, 'steps': 2474, 'loss/train': 26.711990356445312}\n",
      "{'samples': 636800, 'steps': 2487, 'loss/train': 23.85384750366211}\n",
      "{'samples': 640000, 'steps': 2499, 'loss/train': 31.313495635986328}\n",
      "{'loss/eval': 2.2708213329315186, 'perplexity': 9.68735408782959}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'samples': 643200, 'steps': 2512, 'loss/train': 22.02446746826172}\n",
      "{'samples': 646400, 'steps': 2524, 'loss/train': 20.129112243652344}\n",
      "{'samples': 649600, 'steps': 2537, 'loss/train': 17.414730072021484}\n",
      "{'samples': 652800, 'steps': 2549, 'loss/train': 19.14794921875}\n",
      "{'samples': 656000, 'steps': 2562, 'loss/train': 23.21855354309082}\n",
      "{'samples': 659200, 'steps': 2574, 'loss/train': 19.828880310058594}\n",
      "{'samples': 662400, 'steps': 2587, 'loss/train': 33.73101043701172}\n",
      "{'samples': 665600, 'steps': 2599, 'loss/train': 19.425827026367188}\n",
      "{'samples': 668800, 'steps': 2612, 'loss/train': 21.813602447509766}\n",
      "{'samples': 672000, 'steps': 2624, 'loss/train': 25.331449508666992}\n",
      "{'samples': 675200, 'steps': 2637, 'loss/train': 19.86335563659668}\n",
      "{'samples': 678400, 'steps': 2649, 'loss/train': 19.77545928955078}\n",
      "{'samples': 681600, 'steps': 2662, 'loss/train': 23.488609313964844}\n",
      "{'samples': 684800, 'steps': 2674, 'loss/train': 18.18423080444336}\n",
      "{'samples': 688000, 'steps': 2687, 'loss/train': 24.907779693603516}\n",
      "{'samples': 691200, 'steps': 2699, 'loss/train': 22.81930160522461}\n",
      "{'samples': 694400, 'steps': 2712, 'loss/train': 23.56458854675293}\n",
      "{'samples': 697600, 'steps': 2724, 'loss/train': 19.188655853271484}\n",
      "{'samples': 700800, 'steps': 2737, 'loss/train': 26.101459503173828}\n",
      "{'samples': 704000, 'steps': 2749, 'loss/train': 27.380712509155273}\n",
      "{'samples': 707200, 'steps': 2762, 'loss/train': 19.563865661621094}\n",
      "{'samples': 710400, 'steps': 2774, 'loss/train': 20.478145599365234}\n",
      "{'samples': 713600, 'steps': 2787, 'loss/train': 25.93225860595703}\n",
      "{'samples': 716800, 'steps': 2799, 'loss/train': 22.889142990112305}\n",
      "{'samples': 720000, 'steps': 2812, 'loss/train': 24.90359878540039}\n",
      "{'samples': 723200, 'steps': 2824, 'loss/train': 19.82880401611328}\n",
      "{'samples': 726400, 'steps': 2837, 'loss/train': 24.988513946533203}\n",
      "{'samples': 729600, 'steps': 2849, 'loss/train': 20.850704193115234}\n",
      "{'samples': 732800, 'steps': 2862, 'loss/train': 19.48119354248047}\n",
      "{'samples': 736000, 'steps': 2874, 'loss/train': 17.80767059326172}\n",
      "{'samples': 739200, 'steps': 2887, 'loss/train': 20.506145477294922}\n",
      "{'samples': 742400, 'steps': 2899, 'loss/train': 21.996654510498047}\n",
      "{'samples': 745600, 'steps': 2912, 'loss/train': 19.796977996826172}\n",
      "{'samples': 748800, 'steps': 2924, 'loss/train': 22.55772590637207}\n",
      "{'samples': 752000, 'steps': 2937, 'loss/train': 21.89918327331543}\n",
      "{'samples': 755200, 'steps': 2949, 'loss/train': 36.72122573852539}\n",
      "{'samples': 758400, 'steps': 2962, 'loss/train': 22.552040100097656}\n",
      "{'samples': 761600, 'steps': 2974, 'loss/train': 24.6721134185791}\n",
      "{'samples': 764800, 'steps': 2987, 'loss/train': 21.716894149780273}\n",
      "{'samples': 768000, 'steps': 2999, 'loss/train': 17.676740646362305}\n",
      "{'samples': 771200, 'steps': 3012, 'loss/train': 19.459808349609375}\n",
      "{'samples': 774400, 'steps': 3024, 'loss/train': 20.09292984008789}\n",
      "{'samples': 777600, 'steps': 3037, 'loss/train': 22.856678009033203}\n",
      "{'samples': 780800, 'steps': 3049, 'loss/train': 23.549217224121094}\n",
      "{'samples': 784000, 'steps': 3062, 'loss/train': 22.01634407043457}\n",
      "{'samples': 787200, 'steps': 3074, 'loss/train': 21.307292938232422}\n",
      "{'samples': 790400, 'steps': 3087, 'loss/train': 20.63918685913086}\n",
      "{'samples': 793600, 'steps': 3099, 'loss/train': 27.472671508789062}\n",
      "{'samples': 796800, 'steps': 3112, 'loss/train': 20.585180282592773}\n",
      "{'samples': 800000, 'steps': 3124, 'loss/train': 20.69765853881836}\n",
      "{'samples': 803200, 'steps': 3137, 'loss/train': 20.264270782470703}\n",
      "{'samples': 806400, 'steps': 3149, 'loss/train': 19.026609420776367}\n",
      "{'samples': 809600, 'steps': 3162, 'loss/train': 18.461299896240234}\n",
      "{'samples': 812800, 'steps': 3174, 'loss/train': 20.735633850097656}\n",
      "{'samples': 816000, 'steps': 3187, 'loss/train': 19.425233840942383}\n",
      "{'samples': 819200, 'steps': 3199, 'loss/train': 18.046297073364258}\n",
      "{'samples': 822400, 'steps': 3212, 'loss/train': 22.886747360229492}\n",
      "{'samples': 825600, 'steps': 3224, 'loss/train': 16.848209381103516}\n",
      "{'samples': 828800, 'steps': 3237, 'loss/train': 17.13355255126953}\n",
      "{'samples': 832000, 'steps': 3249, 'loss/train': 21.928356170654297}\n",
      "{'samples': 835200, 'steps': 3262, 'loss/train': 17.30652618408203}\n",
      "{'samples': 838400, 'steps': 3274, 'loss/train': 21.60799789428711}\n",
      "{'samples': 841600, 'steps': 3287, 'loss/train': 23.470109939575195}\n",
      "{'samples': 844800, 'steps': 3299, 'loss/train': 17.79522132873535}\n",
      "{'samples': 848000, 'steps': 3312, 'loss/train': 22.751480102539062}\n",
      "{'samples': 851200, 'steps': 3324, 'loss/train': 19.037960052490234}\n",
      "{'samples': 854400, 'steps': 3337, 'loss/train': 21.399991989135742}\n",
      "{'samples': 857600, 'steps': 3349, 'loss/train': 19.672470092773438}\n",
      "{'samples': 860800, 'steps': 3362, 'loss/train': 20.45400619506836}\n",
      "{'samples': 864000, 'steps': 3374, 'loss/train': 20.746749877929688}\n",
      "{'samples': 867200, 'steps': 3387, 'loss/train': 22.5908203125}\n",
      "{'samples': 870400, 'steps': 3399, 'loss/train': 18.444320678710938}\n",
      "{'samples': 873600, 'steps': 3412, 'loss/train': 21.829227447509766}\n",
      "{'samples': 876800, 'steps': 3424, 'loss/train': 21.956335067749023}\n",
      "{'samples': 880000, 'steps': 3437, 'loss/train': 21.47742462158203}\n",
      "{'samples': 883200, 'steps': 3449, 'loss/train': 25.782434463500977}\n",
      "{'samples': 886400, 'steps': 3462, 'loss/train': 23.80942153930664}\n",
      "{'samples': 889600, 'steps': 3474, 'loss/train': 21.83465576171875}\n",
      "{'samples': 892800, 'steps': 3487, 'loss/train': 28.387908935546875}\n",
      "{'samples': 896000, 'steps': 3499, 'loss/train': 19.421751022338867}\n",
      "{'samples': 899200, 'steps': 3512, 'loss/train': 20.085458755493164}\n",
      "{'samples': 902400, 'steps': 3524, 'loss/train': 16.133359909057617}\n",
      "{'samples': 905600, 'steps': 3537, 'loss/train': 22.71222686767578}\n",
      "{'samples': 908800, 'steps': 3549, 'loss/train': 20.07308578491211}\n",
      "{'samples': 912000, 'steps': 3562, 'loss/train': 21.198307037353516}\n",
      "{'samples': 915200, 'steps': 3574, 'loss/train': 20.614818572998047}\n",
      "{'samples': 918400, 'steps': 3587, 'loss/train': 18.490100860595703}\n",
      "{'samples': 921600, 'steps': 3599, 'loss/train': 17.736312866210938}\n",
      "{'samples': 924800, 'steps': 3612, 'loss/train': 18.01513671875}\n",
      "{'samples': 928000, 'steps': 3624, 'loss/train': 22.358966827392578}\n",
      "{'samples': 931200, 'steps': 3637, 'loss/train': 22.029315948486328}\n",
      "{'samples': 934400, 'steps': 3649, 'loss/train': 22.369840621948242}\n",
      "{'samples': 937600, 'steps': 3662, 'loss/train': 22.611188888549805}\n",
      "{'samples': 940800, 'steps': 3674, 'loss/train': 18.452011108398438}\n",
      "{'samples': 944000, 'steps': 3687, 'loss/train': 18.213302612304688}\n",
      "{'samples': 947200, 'steps': 3699, 'loss/train': 19.62124252319336}\n",
      "{'samples': 950400, 'steps': 3712, 'loss/train': 23.58928871154785}\n",
      "{'samples': 953600, 'steps': 3724, 'loss/train': 23.444271087646484}\n",
      "{'samples': 956800, 'steps': 3737, 'loss/train': 18.97531509399414}\n",
      "{'samples': 960000, 'steps': 3749, 'loss/train': 21.78752899169922}\n",
      "{'loss/eval': 2.0882797241210938, 'perplexity': 8.071019172668457}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'samples': 963200, 'steps': 3762, 'loss/train': 18.7039852142334}\n",
      "{'samples': 966400, 'steps': 3774, 'loss/train': 18.308473587036133}\n",
      "{'samples': 969600, 'steps': 3787, 'loss/train': 19.59339141845703}\n",
      "{'samples': 972800, 'steps': 3799, 'loss/train': 21.16069984436035}\n",
      "{'samples': 976000, 'steps': 3812, 'loss/train': 19.145275115966797}\n",
      "{'samples': 979200, 'steps': 3824, 'loss/train': 18.267242431640625}\n",
      "{'samples': 982400, 'steps': 3837, 'loss/train': 20.043155670166016}\n",
      "{'samples': 985600, 'steps': 3849, 'loss/train': 20.359773635864258}\n",
      "{'samples': 988800, 'steps': 3862, 'loss/train': 22.513940811157227}\n",
      "{'samples': 992000, 'steps': 3874, 'loss/train': 18.009235382080078}\n",
      "{'samples': 995200, 'steps': 3887, 'loss/train': 19.075660705566406}\n",
      "{'samples': 998400, 'steps': 3899, 'loss/train': 23.866302490234375}\n",
      "{'samples': 1001600, 'steps': 3912, 'loss/train': 18.74401092529297}\n",
      "{'samples': 1004800, 'steps': 3924, 'loss/train': 19.85009765625}\n",
      "{'samples': 1008000, 'steps': 3937, 'loss/train': 19.052566528320312}\n",
      "{'samples': 1011200, 'steps': 3949, 'loss/train': 19.63467025756836}\n",
      "{'samples': 1014400, 'steps': 3962, 'loss/train': 21.583736419677734}\n",
      "{'samples': 1017600, 'steps': 3974, 'loss/train': 20.671531677246094}\n",
      "{'samples': 1020800, 'steps': 3987, 'loss/train': 21.205577850341797}\n",
      "{'samples': 1024000, 'steps': 3999, 'loss/train': 23.905990600585938}\n",
      "{'samples': 1027200, 'steps': 4012, 'loss/train': 16.772945404052734}\n",
      "{'samples': 1030400, 'steps': 4024, 'loss/train': 21.44976043701172}\n",
      "{'samples': 1033600, 'steps': 4037, 'loss/train': 28.71453094482422}\n",
      "{'samples': 1036800, 'steps': 4049, 'loss/train': 23.24326515197754}\n",
      "{'samples': 1040000, 'steps': 4062, 'loss/train': 20.583606719970703}\n",
      "{'samples': 1043200, 'steps': 4074, 'loss/train': 25.953380584716797}\n",
      "{'samples': 1046400, 'steps': 4087, 'loss/train': 17.013948440551758}\n",
      "{'samples': 1049600, 'steps': 4099, 'loss/train': 21.764158248901367}\n",
      "{'samples': 1052800, 'steps': 4112, 'loss/train': 19.999740600585938}\n",
      "{'samples': 1056000, 'steps': 4124, 'loss/train': 18.737598419189453}\n",
      "{'samples': 1059200, 'steps': 4137, 'loss/train': 18.14260482788086}\n",
      "{'samples': 1062400, 'steps': 4149, 'loss/train': 20.637453079223633}\n",
      "{'samples': 1065600, 'steps': 4162, 'loss/train': 22.69867706298828}\n",
      "{'samples': 1068800, 'steps': 4174, 'loss/train': 19.01224136352539}\n",
      "{'samples': 1072000, 'steps': 4187, 'loss/train': 25.255855560302734}\n",
      "{'samples': 1075200, 'steps': 4199, 'loss/train': 16.35730743408203}\n",
      "{'samples': 1078400, 'steps': 4212, 'loss/train': 19.172012329101562}\n",
      "{'samples': 1081600, 'steps': 4224, 'loss/train': 15.831022262573242}\n",
      "{'samples': 1084800, 'steps': 4237, 'loss/train': 20.029111862182617}\n",
      "{'samples': 1088000, 'steps': 4249, 'loss/train': 15.944086074829102}\n",
      "{'samples': 1091200, 'steps': 4262, 'loss/train': 22.037073135375977}\n",
      "{'samples': 1094400, 'steps': 4274, 'loss/train': 16.358285903930664}\n",
      "{'samples': 1097600, 'steps': 4287, 'loss/train': 29.065881729125977}\n",
      "{'samples': 1100800, 'steps': 4299, 'loss/train': 16.554534912109375}\n",
      "{'samples': 1104000, 'steps': 4312, 'loss/train': 18.50832176208496}\n",
      "{'samples': 1107200, 'steps': 4324, 'loss/train': 25.390960693359375}\n",
      "{'samples': 1110400, 'steps': 4337, 'loss/train': 20.205005645751953}\n",
      "{'samples': 1113600, 'steps': 4349, 'loss/train': 20.153644561767578}\n",
      "{'samples': 1116800, 'steps': 4362, 'loss/train': 18.72161865234375}\n",
      "{'samples': 1120000, 'steps': 4374, 'loss/train': 17.739076614379883}\n",
      "{'samples': 1123200, 'steps': 4387, 'loss/train': 19.249603271484375}\n",
      "{'samples': 1126400, 'steps': 4399, 'loss/train': 19.558935165405273}\n",
      "{'samples': 1129600, 'steps': 4412, 'loss/train': 15.548770904541016}\n",
      "{'samples': 1132800, 'steps': 4424, 'loss/train': 23.916852951049805}\n",
      "{'samples': 1136000, 'steps': 4437, 'loss/train': 20.580509185791016}\n",
      "{'samples': 1139200, 'steps': 4449, 'loss/train': 19.88531494140625}\n",
      "{'samples': 1142400, 'steps': 4462, 'loss/train': 16.474777221679688}\n",
      "{'samples': 1145600, 'steps': 4474, 'loss/train': 23.618078231811523}\n",
      "{'samples': 1148800, 'steps': 4487, 'loss/train': 23.301387786865234}\n",
      "{'samples': 1152000, 'steps': 4499, 'loss/train': 18.126789093017578}\n",
      "{'samples': 1155200, 'steps': 4512, 'loss/train': 18.508211135864258}\n",
      "{'samples': 1158400, 'steps': 4524, 'loss/train': 19.953784942626953}\n",
      "{'samples': 1161600, 'steps': 4537, 'loss/train': 12.954843521118164}\n",
      "{'samples': 1164800, 'steps': 4549, 'loss/train': 19.835256576538086}\n",
      "{'samples': 1168000, 'steps': 4562, 'loss/train': 17.238323211669922}\n",
      "{'samples': 1171200, 'steps': 4574, 'loss/train': 19.013301849365234}\n",
      "{'samples': 1174400, 'steps': 4587, 'loss/train': 18.416950225830078}\n",
      "{'samples': 1177600, 'steps': 4599, 'loss/train': 19.789213180541992}\n",
      "{'samples': 1180800, 'steps': 4612, 'loss/train': 18.556255340576172}\n",
      "{'samples': 1184000, 'steps': 4624, 'loss/train': 22.831655502319336}\n",
      "{'samples': 1187200, 'steps': 4637, 'loss/train': 17.48507308959961}\n",
      "{'samples': 1190400, 'steps': 4649, 'loss/train': 20.948768615722656}\n",
      "{'samples': 1193600, 'steps': 4662, 'loss/train': 19.26416015625}\n",
      "{'samples': 1196800, 'steps': 4674, 'loss/train': 18.520694732666016}\n",
      "{'samples': 1200000, 'steps': 4687, 'loss/train': 20.512887954711914}\n",
      "{'samples': 1203200, 'steps': 4699, 'loss/train': 16.704429626464844}\n",
      "{'samples': 1206400, 'steps': 4712, 'loss/train': 19.13180160522461}\n",
      "{'samples': 1209600, 'steps': 4724, 'loss/train': 14.161970138549805}\n",
      "{'samples': 1212800, 'steps': 4737, 'loss/train': 19.7581844329834}\n",
      "{'samples': 1216000, 'steps': 4749, 'loss/train': 15.909197807312012}\n",
      "{'samples': 1219200, 'steps': 4762, 'loss/train': 20.700950622558594}\n",
      "{'samples': 1222400, 'steps': 4774, 'loss/train': 20.300172805786133}\n",
      "{'samples': 1225600, 'steps': 4787, 'loss/train': 17.41318130493164}\n",
      "{'samples': 1228800, 'steps': 4799, 'loss/train': 16.97783660888672}\n",
      "{'samples': 1232000, 'steps': 4812, 'loss/train': 20.113618850708008}\n",
      "{'samples': 1235200, 'steps': 4824, 'loss/train': 19.569501876831055}\n",
      "{'samples': 1238400, 'steps': 4837, 'loss/train': 19.425094604492188}\n",
      "{'samples': 1241600, 'steps': 4849, 'loss/train': 16.76957893371582}\n",
      "{'samples': 1244800, 'steps': 4862, 'loss/train': 16.622344970703125}\n",
      "{'samples': 1248000, 'steps': 4874, 'loss/train': 24.462053298950195}\n",
      "{'samples': 1251200, 'steps': 4887, 'loss/train': 21.345659255981445}\n",
      "{'samples': 1254400, 'steps': 4899, 'loss/train': 20.93804168701172}\n",
      "{'samples': 1257600, 'steps': 4912, 'loss/train': 19.692630767822266}\n",
      "{'samples': 1260800, 'steps': 4924, 'loss/train': 16.981338500976562}\n",
      "{'samples': 1264000, 'steps': 4937, 'loss/train': 21.046733856201172}\n",
      "{'samples': 1267200, 'steps': 4949, 'loss/train': 15.796152114868164}\n",
      "{'samples': 1270400, 'steps': 4962, 'loss/train': 19.831497192382812}\n",
      "{'samples': 1273600, 'steps': 4974, 'loss/train': 17.470561981201172}\n",
      "{'samples': 1276800, 'steps': 4987, 'loss/train': 20.199254989624023}\n",
      "{'samples': 1280000, 'steps': 4999, 'loss/train': 21.330852508544922}\n",
      "{'loss/eval': 1.9778472185134888, 'perplexity': 7.227168083190918}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renwei/anaconda3/envs/llm/lib/python3.12/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'samples': 1283200, 'steps': 5012, 'loss/train': 15.818708419799805}\n",
      "{'samples': 1286400, 'steps': 5024, 'loss/train': 13.763473510742188}\n",
      "{'samples': 1289600, 'steps': 5037, 'loss/train': 21.070140838623047}\n",
      "{'samples': 1292800, 'steps': 5049, 'loss/train': 19.028566360473633}\n",
      "{'samples': 1296000, 'steps': 5062, 'loss/train': 19.372900009155273}\n",
      "{'samples': 1299200, 'steps': 5074, 'loss/train': 19.606698989868164}\n",
      "{'samples': 1302400, 'steps': 5087, 'loss/train': 18.30612564086914}\n",
      "{'samples': 1305600, 'steps': 5099, 'loss/train': 21.161514282226562}\n",
      "{'samples': 1308800, 'steps': 5112, 'loss/train': 19.043243408203125}\n",
      "{'samples': 1312000, 'steps': 5124, 'loss/train': 17.697551727294922}\n",
      "{'samples': 1315200, 'steps': 5137, 'loss/train': 19.70696449279785}\n",
      "{'samples': 1318400, 'steps': 5149, 'loss/train': 22.47640609741211}\n",
      "{'samples': 1321600, 'steps': 5162, 'loss/train': 22.29026985168457}\n",
      "{'samples': 1324800, 'steps': 5174, 'loss/train': 28.1436767578125}\n",
      "{'samples': 1328000, 'steps': 5187, 'loss/train': 16.13973617553711}\n",
      "{'samples': 1331200, 'steps': 5199, 'loss/train': 21.335283279418945}\n",
      "{'samples': 1334400, 'steps': 5212, 'loss/train': 19.06922721862793}\n",
      "{'samples': 1337600, 'steps': 5224, 'loss/train': 20.915132522583008}\n",
      "{'samples': 1340800, 'steps': 5237, 'loss/train': 17.867496490478516}\n",
      "{'samples': 1344000, 'steps': 5249, 'loss/train': 23.040761947631836}\n",
      "{'samples': 1347200, 'steps': 5262, 'loss/train': 20.21550941467285}\n",
      "{'samples': 1350400, 'steps': 5274, 'loss/train': 17.241546630859375}\n",
      "{'samples': 1353600, 'steps': 5287, 'loss/train': 14.43136215209961}\n",
      "{'samples': 1356800, 'steps': 5299, 'loss/train': 19.105026245117188}\n",
      "{'samples': 1360000, 'steps': 5312, 'loss/train': 20.092422485351562}\n",
      "{'samples': 1363200, 'steps': 5324, 'loss/train': 14.968118667602539}\n",
      "{'samples': 1366400, 'steps': 5337, 'loss/train': 17.535444259643555}\n",
      "{'samples': 1369600, 'steps': 5349, 'loss/train': 17.02167510986328}\n",
      "{'samples': 1372800, 'steps': 5362, 'loss/train': 16.971454620361328}\n",
      "{'samples': 1376000, 'steps': 5374, 'loss/train': 20.869312286376953}\n",
      "{'loss/eval': 1.9539766311645508, 'perplexity': 7.0566935539245605}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "samples_per_step = 32  # Should be the batch size of `train_dataloader`.\n",
    "gradient_accumulation_steps = 8\n",
    "eval_steps = 1_250  # 5_000\n",
    "\n",
    "model.train()\n",
    "completed_steps = 0\n",
    "for epoch in range(num_train_epochs):\n",
    "    for step, batch in tqdm(\n",
    "        enumerate(train_dataloader, start=1), total=num_training_steps\n",
    "    ):\n",
    "        logits = model(batch[\"input_ids\"]).logits\n",
    "        loss = keytoken_weighted_loss(batch[\"input_ids\"], logits, keytoken_ids)\n",
    "        if step % 100 == 0:\n",
    "            accelerator.print(\n",
    "                {\n",
    "                    \"samples\": step * samples_per_step,\n",
    "                    \"steps\": completed_steps,\n",
    "                    \"loss/train\": loss.item() * gradient_accumulation_steps,\n",
    "                }\n",
    "            )\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        accelerator.backward(loss)\n",
    "        if step % gradient_accumulation_steps == 0:\n",
    "            accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            completed_steps += 1\n",
    "        if (\n",
    "            step % (eval_steps * gradient_accumulation_steps)\n",
    "        ) == 0 or step == num_training_steps:\n",
    "            eval_loss, perplexity = evaluate()\n",
    "            accelerator.print({\"loss/eval\": eval_loss, \"perplexity\": perplexity})\n",
    "            model.train()\n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "            if accelerator.is_main_process:\n",
    "                tokenizer.save_pretrained(output_dir)\n",
    "                repo.push_to_hub(\n",
    "                    commit_message=f\"Training in progress step {step}\", blocking=False\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
